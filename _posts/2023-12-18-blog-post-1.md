---
title: 'Sklearn Introduction'
date: 2023-12-18
permalink: /posts/2023/12/blog-post-1/
tags:
  - Sklearn
  - Machine Learning
  - Colab
---
<a href="https://colab.research.google.com/github/giangdip2410/Research-Stuff/blob/main/CPSC5440_Assigment1_JGM667.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Introduction to Sklearn

### 1.  Making of a proper dataset with 3 languages


```python
# mount notebook to drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
```

    Mounted at /content/drive



```python
# change dir to data folder
# data link: English - https://drive.google.com/file/d/1-_Bb3PavAML6HqoUJkpyg-zOb1bYZgWe/view?usp=sharing
# German - https://drive.google.com/file/d/1-KljKd9thoKEKdNnf6zZKDvmff8_NKUi/view?usp=sharing
# Vietnamese - https://drive.google.com/file/d/1-7A26XYVi1sbr3tmvlEqnH8SKuzMYMfM/view?usp=sharing
import os
os.chdir("drive/MyDrive/UTC/Intro_ML_Project/Assignment1/")
```


```python
#require libray
import pandas as pd 
import numpy as np
import sklearn 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns 
import plotly.express as px
import plotly.graph_objects as go
import warnings
warnings.filterwarnings('ignore')
```


```python
#function to create data

def generate_data(filename, k_letter=5):
    #read files
    if filename != 'german.txt':
        f = open(filename)
        list_words = f.readlines()
    else:
        df_w = pd.read_csv(filename, encoding="ISO-8859-1", header=None)
        df_w = df_w.dropna()
        list_words = df_w.iloc[:,0].values
    #collect feature and label
    feature_dataset = []
    target_dataset = []
    for word in list_words:
        # Clean the line by removing the new-line character
        if filename != 'german.txt':
            cleaned_word = word.replace('\n', '')
        else:
            cleaned_word = word
        # Check if the length of the cleaned word is equal to 5, to get words with 5 characters.
        if len(cleaned_word) == k_letter:
            # Make an array for converting word to ord representation
            word_to_ord = []
            
            # Iterate through the cleaned word characters, ord the character, and append it to the word_to_ord list.
            for char in cleaned_word:
                word_to_ord.append(ord(char))
                
            # Append the ord'ed word to the training dataset
            feature_dataset.append(word_to_ord)
            
            # Append the correct answer to the target dataset
            if filename == "english.txt":
                target_dataset.append(0)
            elif filename == "german.txt":
                target_dataset.append(1)
            else:
                target_dataset.append(2)
    return np.array(feature_dataset), np.array(target_dataset)
```


```python
# #generate english data
en_feat, en_target = generate_data("english.txt", k_letter=5)
#generate german data
gm_feat, gm_target = generate_data("german.txt", k_letter=5)
# #generate vietnamese data
vn_feat, vn_target = generate_data("vietnamese.txt", k_letter=5)
#combine as one data
all_feat = np.concatenate([en_feat, gm_feat,vn_feat], axis=0)
all_target = np.concatenate([en_target, gm_target,vn_target], axis=0)
```


```python
#check shape of dataset 
print(en_feat.shape, gm_feat.shape, vn_feat.shape, all_feat.shape)
print(en_target.shape, gm_target.shape, vn_target.shape, all_target.shape)
```

    (11435, 5) (3234, 5) (3025, 5) (17694, 5)
    (11435,) (3234,) (3025,) (17694,)


### 2.Making a training and testing dataset split.


```python
#split train test
X_train, X_test, y_train, y_test = train_test_split(all_feat, all_target, test_size=0.2, random_state=42, shuffle=True, stratify=all_target)
```


```python
#check shape data after split
print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
```

    (14155, 5) (14155,) (3539, 5) (3539,)


### 3. Being able to train the models and make predictions.


```python
#KNN model
knn = KNeighborsClassifier(n_neighbors=4, metric='euclidean') #chose 3 of neighbors, euclidean metrix 
#training model
knn.fit(X_train, y_train)
#predict for test data
y_pred_knn = knn.predict(X_test)
#print accuracy on test_data
knn_acc = round(accuracy_score(y_test, y_pred_knn) * 100,1) 
print("Accuracy of KNN on test data: ", knn_acc)
#summary classification report
print(classification_report(y_test, y_pred_knn))
```

    Accuracy of KNN on test data:  89.7
                  precision    recall  f1-score   support
    
               0       0.88      0.98      0.93      2287
               1       0.88      0.59      0.70       647
               2       0.98      0.91      0.94       605
    
        accuracy                           0.90      3539
       macro avg       0.91      0.83      0.86      3539
    weighted avg       0.90      0.90      0.89      3539
    



```python
#SVN model
sv = svm.SVC(C=5.0, kernel='rbf') #chose kernel rbf
#training model
sv.fit(X_train, y_train)
#predict for test data
y_pred_svm = sv.predict(X_test)
#print accuracy on test_data
sv_acc = round(accuracy_score(y_test, y_pred_svm)*100,1)
print("Accuracy of SVM on test data: ", sv_acc)
#summary classification report
print(classification_report(y_test, y_pred_svm))
```

    Accuracy of SVM on test data:  79.5
                  precision    recall  f1-score   support
    
               0       0.77      1.00      0.87      2287
               1       0.76      0.13      0.22       647
               2       0.99      0.74      0.85       605
    
        accuracy                           0.80      3539
       macro avg       0.84      0.62      0.64      3539
    weighted avg       0.80      0.80      0.75      3539
    



```python
#MLP model
mlp = MLPClassifier(
    hidden_layer_sizes=(16,),
    activation = 'logistic',
    max_iter=100,
    alpha=1e-4,
    solver="sgd",
    verbose=10,
    random_state=42,
    learning_rate_init=0.02,
)   #chose kernel rbf
#training model
mlp.fit(X_train, y_train)
#predict for test data
y_pred_mlp = mlp.predict(X_test)
#print accuracy on test_data
mlp_acc = round(accuracy_score(y_test, y_pred_mlp)*100,1)
print("Accuracy of MLP on test data: ", mlp_acc)
#summary classification report
print(classification_report(y_test, y_pred_mlp))
```

    Iteration 1, loss = 0.78381191
    Iteration 2, loss = 0.57109453
    Iteration 3, loss = 0.52196303
    Iteration 4, loss = 0.47524718
    Iteration 5, loss = 0.49233903
    Iteration 6, loss = 0.44109614
    Iteration 7, loss = 0.41557871
    Iteration 8, loss = 0.44645181
    Iteration 9, loss = 0.56176867
    Iteration 10, loss = 0.55387634
    Iteration 11, loss = 0.54611552
    Iteration 12, loss = 0.54698724
    Iteration 13, loss = 0.53984274
    Iteration 14, loss = 0.53166853
    Iteration 15, loss = 0.52611560
    Iteration 16, loss = 0.52318489
    Iteration 17, loss = 0.51651663
    Iteration 18, loss = 0.51654785
    Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
    Accuracy of MLP on test data:  81.0
                  precision    recall  f1-score   support
    
               0       0.78      1.00      0.87      2287
               1       0.94      0.12      0.22       647
               2       0.98      0.83      0.90       605
    
        accuracy                           0.81      3539
       macro avg       0.90      0.65      0.66      3539
    weighted avg       0.84      0.81      0.76      3539
    


### 4. Graph the results of each model (KNN, SVM, MLP) 


```python
#install kaleido library for save result
!pip install -U kaleido -q
```


```python
# Label text for model
labels = ["KNN", "SVM", "MLP"]
# model results
results = [knn_acc, sv_acc, mlp_acc]
#create dataframe
df_results = pd.DataFrame.from_dict({"models": labels, "results": results})
fig = go.Figure()
#plot model 
fig.add_trace(go.Bar(
x=results,
y=labels,
marker=dict(
    color='rgba(50, 171, 96, 0.6)',
    line=dict(
        color='rgba(50, 171, 96, 1.0)',
        width=1),
),
orientation='h', text=results
))
#change postion of data label
fig.update_traces(textposition='outside')
# config charts
fig.update_layout(
    title='Machine Learning Models Comparison',
    xaxis_title="Accuracy",
    yaxis_title="Models",
    legend=dict(x=0.029, y=1.038, font_size=10),
    margin=dict(l=100, r=20, t=70, b=70),
    paper_bgcolor='rgb(248, 248, 255)',
    plot_bgcolor='rgb(248, 248, 255)',
    autosize=False,
    width=800,
    height=450,
)
# Display the graph
fig.show()
#save picture result
fig.write_image("models_result.png")
```


<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-2.8.3.min.js"></script>                <div id="ae4e2a42-444c-4d4e-aca1-7c9a5ef6d00b" class="plotly-graph-div" style="height:450px; width:800px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("ae4e2a42-444c-4d4e-aca1-7c9a5ef6d00b")) {                    Plotly.newPlot(                        "ae4e2a42-444c-4d4e-aca1-7c9a5ef6d00b",                        [{"marker":{"color":"rgba(50, 171, 96, 0.6)","line":{"color":"rgba(50, 171, 96, 1.0)","width":1}},"orientation":"h","text":["89.7","79.5","81.0"],"x":[89.7,79.5,81.0],"y":["KNN","SVM","MLP"],"type":"bar","textposition":"outside"}],                        {"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"legend":{"font":{"size":10},"x":0.029,"y":1.038},"margin":{"l":100,"r":20,"t":70,"b":70},"title":{"text":"Machine Learning Models Comparison"},"xaxis":{"title":{"text":"Accuracy"}},"yaxis":{"title":{"text":"Models"}},"paper_bgcolor":"rgb(248, 248, 255)","plot_bgcolor":"rgb(248, 248, 255)","autosize":false,"width":800,"height":450},                        {"responsive": true}                    ).then(function(){

var gd = document.getElementById('ae4e2a42-444c-4d4e-aca1-7c9a5ef6d00b');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>
</body>
</html>



```python

```


```python

```


```python

```
